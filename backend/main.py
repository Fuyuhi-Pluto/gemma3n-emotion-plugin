# backend/main.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel
from datetime import datetime
from typing import Dict, Any, Optional
from io import BytesIO
from transformers import AutoProcessor, Gemma3nForConditionalGeneration
import time
import os
import json
import base64
import matplotlib.pyplot as plt
import numpy as np

from core.storage import save_mood_entry, get_mood_history, export_history
from core.emotional_chat_function import EmotionalChatHandler
from core.emotion_analyzer_enhanced import EmotionAnalyzer
from utils.multi_plutchik_plotter import PlutchikPlotter

print("ğŸ§  å½“å‰è¿è¡Œæ–‡ä»¶ï¼š", os.path.abspath(__file__))
print("ğŸ§  å½“å‰ Python è¿›ç¨‹ PID:", os.getpid())
print("ğŸ§  å½“å‰æ–‡ä»¶æœ€åä¿®æ”¹æ—¶é—´:", time.ctime(os.path.getmtime(__file__)))

MODEL = None
PROCESSOR = None
CHAT_HANDLER = None
# æ·»åŠ å¿«é€Ÿæµ‹è¯•æ¨¡å¼
QUICK_TEST_MODE = False  # ğŸ”§ è·³è¿‡LLMåˆ†æï¼Œåªæµ‹è¯•æ¥å£

def get_chat_handler():
    global CHAT_HANDLER
    if CHAT_HANDLER is None:
        MODEL, PROCESSOR = get_models()
        CHAT_HANDLER = EmotionalChatHandler(MODEL, PROCESSOR)
    return CHAT_HANDLER

def get_models():
    """æ‡’åŠ è½½æ¨¡å‹ï¼Œåªåœ¨ç¬¬ä¸€æ¬¡ä½¿ç”¨æ—¶åŠ è½½"""
    global MODEL, PROCESSOR
    if MODEL is None or PROCESSOR is None:
        print("ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹...")
        model_id = "google/gemma-3n-e2b-it"
        MODEL = Gemma3nForConditionalGeneration.from_pretrained(model_id).to("cpu").eval()
        PROCESSOR = AutoProcessor.from_pretrained(model_id)
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    return MODEL, PROCESSOR

app = FastAPI(
    title="Emotion Plugin API",
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json"
)

# æŒ‚è½½å‰ç«¯é™æ€æ–‡ä»¶
app.mount("/static", StaticFiles(directory="../frontend"), name="static")

# æ·»åŠ ä¸»é¡µè·¯ç”±
@app.get("/")
async def read_index():
    return FileResponse('../frontend/index.html')

# æ·»åŠ CORSä¸­é—´ä»¶ï¼Œå…è®¸æ‰€æœ‰æ¥æºè·¨åŸŸè¯·æ±‚
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # æˆ–æŒ‡å®šå‰ç«¯åœ°å€å¦‚ ["http://127.0.0.1:5500"]
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class MoodInput(BaseModel):
    text: str
    use_llm: bool = True
    save: bool = False  # å‰ç«¯æŒ‰é’®ä¼ å…¥ï¼Œå†³å®šæ˜¯å¦ä¿å­˜
    enable_conversation: bool = False  # æ–°å¢
    conversation_id: Optional[str] = None  # æ–°å¢

class MoodRecord(BaseModel):
    timestamp: str
    input_mood: str
    mood_category: str





@app.post("/chat")
def chat_with_agent(mood_input: MoodInput):
    # ğŸ”§ å¿«é€Ÿæµ‹è¯•æ¨¡å¼
    if QUICK_TEST_MODE:
        if mood_input.conversation_id:
            # ç»§ç»­å¯¹è¯çš„ç®€å•å›å¤
            ai_response = f"åç«¯æ”¶åˆ°ç»§ç»­å¯¹è¯: '{mood_input.text}'"
            return {
                "timestamp": datetime.now().isoformat(),
                "conversation_enabled": True,
                "conversation_id": mood_input.conversation_id,
                "ai_response": ai_response
            }
        else:
            # æ–°å¯¹è¯
            # åˆ›å»ºæµ‹è¯•å›¾ç‰‡
           
            fig, ax = plt.subplots(figsize=(6, 6))
            
            # ç»˜åˆ¶ä¸€ä¸ªç®€å•çš„æƒ…ç»ªè½®ç›˜æµ‹è¯•å›¾
            emotions = ['joy', 'trust', 'fear', 'surprise', 'sadness', 'disgust', 'anger', 'anticipation']
            values = [0.3, 0.5, 0.2, 0.8, 0.6, 0.1, 0.4, 0.7]
            colors = ['gold', 'green', 'blue', 'pink', 'navy', 'lightgreen', 'red', 'orange']
            
            # åˆ›å»ºæåæ ‡å›¾
            angles = np.linspace(0, 2*np.pi, len(emotions), endpoint=False).tolist()
            values += values[:1]  # é—­åˆå›¾å½¢
            angles += angles[:1]
            
            ax = plt.subplot(111, projection='polar')
            ax.plot(angles, values, 'o-', linewidth=2, color='navy')
            ax.fill(angles, values, alpha=0.25, color='lightblue')
            ax.set_xticks(angles[:-1])
            ax.set_xticklabels(emotions)
            ax.set_ylim(0, 1)
            ax.set_title('Test Emotion Wheel', y=1.08)
            
            plt.tight_layout()
            
            # è½¬æ¢ä¸ºbase64
            buf = io.BytesIO()
            plt.savefig(buf, format='png', bbox_inches='tight', dpi=100)
            buf.seek(0)
            test_image = base64.b64encode(buf.read()).decode('utf-8')
            buf.close()
            plt.close()
            return {
                "timestamp": datetime.now().isoformat(),
                "intensity_labels": {"joy": "Joy", "sadness": "Sadness"},
                "emotion_scores": {"joy": 4, "sadness": 2},
                "emotion_reasons": {"joy": "reason1", "sadness": "reason2"},
                "plutchik_image": test_image,
                "conversation_enabled": True,
                "conversation_id": "backend_test_123",
                "ai_response": "response from backend test"
            }
    user_text = mood_input.text
    # mood_result = classify_mood_with_gemma3(user_text,save_result=mood_input.save)
    timestamp = datetime.now().isoformat()

    MODEL, PROCESSOR = get_models()
    if not mood_input.conversation_id:
        analyzer = EmotionAnalyzer(user_text, MODEL, PROCESSOR, save_result=mood_input.save)
            
        # ç»˜åˆ¶æƒ…ç»ªå›¾è¡¨ï¼ˆå³ä½¿æ²¡æœ‰æƒ…ç»ªä¹Ÿèƒ½ç”Ÿæˆç©ºå›¾è¡¨ï¼‰
        emotion_sets = [analyzer.normalized, analyzer.blended_emotions]
        plotter = PlutchikPlotter(emotion_sets)
        
        fig = plotter.draw_multiple_plutchik_wheels(return_fig=True)
        buf = BytesIO()
        fig.savefig(buf, format="png", bbox_inches="tight", transparent=True)
        buf.seek(0)
        base64_image = base64.b64encode(buf.read()).decode("utf-8")
        buf.close()

        result = {
                "timestamp": timestamp,
                "input_mood": user_text,
                
                # ğŸ”§ ä¿®æ­£å­—æ®µæ˜ å°„
                "intensity_labels": analyzer.classification,     # å‰ç«¯éœ€è¦çš„å¼ºåº¦æ ‡ç­¾
                "emotion_scores": analyzer.base_scores,          # å‰ç«¯éœ€è¦çš„åŸºç¡€è¯„åˆ†
                "emotion_reasons": analyzer.emotion_reasons,      # æƒ…ç»ªåŸå› è¯´æ˜
                
                # ä¿ç•™å…¶ä»–æœ‰ç”¨å­—æ®µ
                "normalized_emotions": analyzer.normalized,       # æ ‡å‡†åŒ–æƒ…ç»ª
                "blended_emotions": analyzer.blended_emotions,    # æ··åˆæƒ…ç»ª
                "plutchik_image": base64_image,                  # æƒ…ç»ªå›¾è¡¨
                
                # å¯¹è¯å­—æ®µé»˜è®¤å€¼
                "conversation_enabled": False,
                "conversation_id": None,
                "ai_response": None
            }
    else:
        # ç»§ç»­å¯¹è¯æ—¶çš„ç®€åŒ–ç»“æœ
        result = {
            "timestamp": timestamp,
            "input_mood": user_text,
            "conversation_continue": True,
            # ä¿æŒå¯¹è¯å­—æ®µçš„é»˜è®¤å€¼
            "conversation_enabled": False,
            "conversation_id": None,
            "ai_response": None
        }

    if mood_input.enable_conversation:
        try:
            #chat_handler = EmotionalChatHandler(MODEL, PROCESSOR)
            chat_handler = get_chat_handler()  # ä½¿ç”¨å…¨å±€å®ä¾‹
            
            if mood_input.conversation_id:
                # ç»§ç»­å¯¹è¯
                print(f"ğŸ”§ ç»§ç»­å¯¹è¯ï¼ŒID: {mood_input.conversation_id}")
                print(f"ğŸ”§ å½“å‰å­˜å‚¨çš„å¯¹è¯: {getattr(chat_handler, 'active_conversations', {}).keys()}")
                ai_response = chat_handler.continue_emotional_conversation(
                    mood_input.conversation_id, user_text
                )
                conversation_id = mood_input.conversation_id
            else:
                # å¼€å§‹æ–°å¯¹è¯
                emotion_info = analyzer.emotion_info
                reference_response = analyzer.emotion_reasons
                conversation_id, ai_response = chat_handler.start_emotional_conversation(
                    user_text, emotion_info, reference_response
                )
            
            # æ·»åŠ å¯¹è¯ç›¸å…³å­—æ®µ
            result.update({
                "conversation_enabled": True,
                "conversation_id": conversation_id,
                "ai_response": ai_response
            })
            
        except Exception as e:
            print(f"âŒ å¯¹è¯åŠŸèƒ½å‡ºé”™: {e}")
            result.update({
                "conversation_enabled": False,
                "conversation_error": str(e)
            })
    return result



@app.get("/history")
def view_history() -> Dict[str, Any]:
    records = get_mood_history()

    return {"records": records}

@app.get("/stats")
def mood_stats() -> Dict[str, Any]:
    records = get_mood_history()
    # è¿™é‡Œå¯ä»¥æ·»åŠ ç»Ÿè®¡å’Œå¯è§†åŒ–é€»è¾‘
    stats = {}  # TODO: å®ç°ç»Ÿè®¡
    return {"stats": stats}

@app.get("/export")
def export_diary(format: str = "csv") -> Dict[str, Any]:
    records = get_mood_history()
    file_content = export_history(records, format)
    return {"file": file_content, "format": format}



if __name__ == "__main__":
    import uvicorn
    import webbrowser
    import threading
    import time
    
    def open_browser():
        time.sleep(2)  # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
        webbrowser.open('http://localhost:8888')
    
    # å¯åŠ¨æµè§ˆå™¨çº¿ç¨‹
    threading.Thread(target=open_browser, daemon=True).start()
    
    print("ğŸš€ å¯åŠ¨æœåŠ¡å™¨...")
    print("ğŸŒ åº”ç”¨å°†åœ¨ http://localhost:8888 è‡ªåŠ¨æ‰“å¼€")
    
    uvicorn.run(
        "main:app",
        host="127.0.0.1",
        port=8888,
        reload=True
    )

# if __name__ == "__main__":
#     import uvicorn
#     uvicorn.run(
#         "main:app",
#         host="127.0.0.1",
#         port=8888,
#         reload=True
#     )
